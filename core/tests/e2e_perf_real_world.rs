// AUTO-GENERATED by scripts/generate_real_world_perf_tests.py
// Do not edit by hand.

#![cfg(feature = "perf-metrics")]
#![allow(dead_code, non_snake_case)]

use excel_diff::perf::DiffMetrics;
use excel_diff::{
    CallbackSink, ContainerLimits, DiffConfig, DiffSink, JsonLinesSink, PbixPackage,
    WorkbookPackage,
};
use serde::Deserialize;
use std::fs::File;
use std::io::Read;
use std::path::{Path, PathBuf};

#[derive(Debug, Deserialize)]
struct CorpusIndex {
    version: u32,
    files: Vec<CorpusFileEntry>,
}

#[derive(Debug, Deserialize)]
struct CorpusFileEntry {
    sha256: Option<String>,
    extension: Option<String>,
    filename: Option<String>,
    dataset_id: Option<String>,
    size_bytes: Option<u64>,
}

fn corpus_dir() -> PathBuf {
    std::env::var_os("TABULENSIS_REAL_WORLD_CORPUS_DIR")
        .map(PathBuf::from)
        .unwrap_or_else(|| {
            PathBuf::from(env!("CARGO_MANIFEST_DIR"))
                .join("..")
                .join("corpus_public")
        })
}

fn load_corpus_index() -> CorpusIndex {
    let index_path = corpus_dir().join("index.json");
    let bytes = std::fs::read(&index_path).unwrap_or_else(|e| {
        panic!("failed to read corpus index {}: {e}", index_path.display());
    });
    serde_json::from_slice(&bytes).unwrap_or_else(|e| {
        panic!("failed to parse corpus index {}: {e}", index_path.display());
    })
}

fn resolve_dataset_path(dataset_id: &str) -> PathBuf {
    let index = load_corpus_index();
    for entry in &index.files {
        if entry.dataset_id.as_deref() == Some(dataset_id) {
            let filename = entry.filename.as_deref().unwrap_or_else(|| {
                panic!("corpus entry for {dataset_id} missing filename in index.json");
            });
            return corpus_dir().join(filename);
        }
    }
    panic!("dataset_id not found in corpus index: {dataset_id}");
}

fn read_file_with_size(path: &Path) -> (Vec<u8>, u64) {
    let bytes = std::fs::metadata(path).map(|m| m.len()).unwrap_or(0);
    let mut file =
        File::open(path).unwrap_or_else(|e| panic!("failed to open {}: {e}", path.display()));
    let mut data = Vec::with_capacity(bytes.min(usize::MAX as u64) as usize);
    file.read_to_end(&mut data)
        .unwrap_or_else(|e| panic!("failed to read {}: {e}", path.display()));
    (data, bytes)
}

fn log_perf_metric(
    case_id: &str,
    metrics: &DiffMetrics,
    old_bytes: u64,
    new_bytes: u64,
    op_count: usize,
    workload_id: u32,
) {
    let total_input_bytes = old_bytes.saturating_add(new_bytes);
    println!(
        "PERF_METRIC {case_id} total_time_ms={} parse_time_ms={} diff_time_ms={} signature_build_time_ms={} move_detection_time_ms={} alignment_time_ms={} cell_diff_time_ms={} op_emit_time_ms={} report_serialize_time_ms={} peak_memory_bytes={} grid_storage_bytes={} string_pool_bytes={} op_buffer_bytes={} alignment_buffer_bytes={} rows_processed={} cells_compared={} anchors_found={} moves_detected={} hash_lookups_est={} allocations_est={} old_bytes={} new_bytes={} total_input_bytes={} op_count={} workload_id={}",
        metrics.total_time_ms,
        metrics.parse_time_ms,
        metrics.diff_time_ms,
        metrics.signature_build_time_ms,
        metrics.move_detection_time_ms,
        metrics.alignment_time_ms,
        metrics.cell_diff_time_ms,
        metrics.op_emit_time_ms,
        metrics.report_serialize_time_ms,
        metrics.peak_memory_bytes,
        metrics.grid_storage_bytes,
        metrics.string_pool_bytes,
        metrics.op_buffer_bytes,
        metrics.alignment_buffer_bytes,
        metrics.rows_processed,
        metrics.cells_compared,
        metrics.anchors_found,
        metrics.moves_detected,
        metrics.hash_lookups_est,
        metrics.allocations_est,
        old_bytes,
        new_bytes,
        total_input_bytes,
        op_count,
        workload_id
    );
}

struct CountingSink {
    inner: Box<dyn DiffSink>,
    count: usize,
}

impl CountingSink {
    fn new(inner: Box<dyn DiffSink>) -> Self {
        Self { inner, count: 0 }
    }
}

impl DiffSink for CountingSink {
    fn begin(&mut self, pool: &excel_diff::StringPool) -> Result<(), excel_diff::DiffError> {
        self.inner.begin(pool)
    }

    fn emit(&mut self, op: excel_diff::DiffOp) -> Result<(), excel_diff::DiffError> {
        self.count += 1;
        self.inner.emit(op)
    }

    fn finish(&mut self) -> Result<(), excel_diff::DiffError> {
        self.inner.finish()
    }
}

#[derive(Clone, Copy)]
enum Workload {
    StreamingFast = 0,
    StreamingJsonl = 1,
}

fn run_case(case_id: &str, dataset_a: &str, dataset_b: &str, workload: Workload, expect_ops: bool) {
    let path_a = resolve_dataset_path(dataset_a);
    let path_b = resolve_dataset_path(dataset_b);
    let (old_data, old_bytes) = read_file_with_size(&path_a);
    let (new_data, new_bytes) = read_file_with_size(&path_b);

    let config = DiffConfig::default();

    let ext_a = path_a
        .extension()
        .and_then(|s| s.to_str())
        .unwrap_or("")
        .to_lowercase();
    let ext_b = path_b
        .extension()
        .and_then(|s| s.to_str())
        .unwrap_or("")
        .to_lowercase();
    assert_eq!(
        ext_a, ext_b,
        "dataset A/B extensions should match for a case"
    );

    if ext_a == "pbix" || ext_a == "pbit" {
        let pkg_a = PbixPackage::open(std::io::Cursor::new(old_data)).expect("pbix A should parse");
        let pkg_b = PbixPackage::open(std::io::Cursor::new(new_data)).expect("pbix B should parse");

        let mut sink = match workload {
            Workload::StreamingFast => CountingSink::new(Box::new(CallbackSink::new(|_op| {}))),
            Workload::StreamingJsonl => {
                CountingSink::new(Box::new(JsonLinesSink::new(std::io::sink())))
            }
        };

        let summary = pkg_a
            .diff_streaming(&pkg_b, &config, &mut sink)
            .expect("pbix diff_streaming should succeed");

        assert!(summary.complete, "expected pbix diff to complete");
        assert_eq!(
            summary.op_count, sink.count,
            "op_count should match sink-emitted ops"
        );
        if expect_ops {
            assert!(summary.op_count > 0, "expected ops for case");
        } else {
            assert_eq!(summary.op_count, 0, "expected no ops for case");
        }

        let metrics = summary.metrics.expect("expected perf metrics");
        log_perf_metric(
            case_id,
            &metrics,
            old_bytes,
            new_bytes,
            summary.op_count,
            workload as u32,
        );
        return;
    }

    // Default: OpenXML workbooks.
    let limits = ContainerLimits {
        max_entries: 10_000,
        max_part_uncompressed_bytes: 512 * 1024 * 1024,
        max_total_uncompressed_bytes: 1024 * 1024 * 1024,
    };

    let mut sink = match workload {
        Workload::StreamingFast => CountingSink::new(Box::new(CallbackSink::new(|_op| {}))),
        Workload::StreamingJsonl => {
            CountingSink::new(Box::new(JsonLinesSink::new(std::io::sink())))
        }
    };

    let summary = WorkbookPackage::diff_openxml_streaming_fast_with_limits(
        std::io::Cursor::new(old_data),
        std::io::Cursor::new(new_data),
        limits,
        &config,
        &mut sink,
    )
    .expect("diff_openxml_streaming_fast_with_limits should succeed");

    assert!(summary.complete, "expected streaming diff to complete");
    assert_eq!(
        summary.op_count, sink.count,
        "op_count should match sink-emitted ops"
    );
    if expect_ops {
        assert!(summary.op_count > 0, "expected at least one op");
    } else {
        assert_eq!(summary.op_count, 0, "expected no ops");
    }

    let metrics = summary.metrics.expect("expected perf metrics");
    log_perf_metric(
        case_id,
        &metrics,
        old_bytes,
        new_bytes,
        summary.op_count,
        workload as u32,
    );
}

#[test]
#[ignore = "Real-world perf case: run via scripts/export_real_world_metrics.py (or cargo test --features perf-metrics -- --ignored)"]
fn rw_ons_lms_v141__derived_numeric_edits10_seed1__jsonl() {
    run_case(
        "rw_ons_lms_v141__derived_numeric_edits10_seed1__jsonl",
        "rw_ons_lms_v141",
        "derived_b__rw_ons_lms_v141__derived_numeric_edits10_seed1__jsonl",
        Workload::StreamingJsonl,
        true,
    );
}

#[test]
#[ignore = "Real-world perf case: run via scripts/export_real_world_metrics.py (or cargo test --features perf-metrics -- --ignored)"]
fn rw_ons_lms_v141__diff_vs_v140__streaming_fast() {
    run_case(
        "rw_ons_lms_v141__diff_vs_v140__streaming_fast",
        "rw_ons_lms_v140",
        "rw_ons_lms_v141",
        Workload::StreamingFast,
        true,
    );
}

#[test]
#[ignore = "Real-world perf case: run via scripts/export_real_world_metrics.py (or cargo test --features perf-metrics -- --ignored)"]
fn rw_ons_lx_v5__derived_row_block_swap20_seed1__streaming_fast() {
    run_case(
        "rw_ons_lx_v5__derived_row_block_swap20_seed1__streaming_fast",
        "rw_ons_lx_v5",
        "derived_b__rw_ons_lx_v5__derived_row_block_swap20_seed1__streaming_fast",
        Workload::StreamingFast,
        true,
    );
}

#[test]
#[ignore = "Real-world perf case: run via scripts/export_real_world_metrics.py (or cargo test --features perf-metrics -- --ignored)"]
fn rw_ons_lx_v5__identical__streaming_fast() {
    run_case(
        "rw_ons_lx_v5__identical__streaming_fast",
        "rw_ons_lx_v5",
        "rw_ons_lx_v5",
        Workload::StreamingFast,
        false,
    );
}
