Tabulensis - Frequently Used Commands
=====================================

CYCLE SETUP
-----------
After creating a new git branch (e.g., git checkout -b 2025-11-27-feature-name):

    python docs/setup_cycle.py

Creates:
  - docs/meta/logs/[branch-name]/checklist.md
  - docs/meta/plans/[branch-name]/spec.md
  - docs/meta/plans/[branch-name]/decision.yaml


PLANNING (Generate context for Planner Agent)
---------------------------------------------
    python docs/meta/prompts/generate_review_context.py --plan

Collates all context files and copies planner instruction to clipboard.
Upload the files from docs/meta/prompts/planner_context/ to your LLM.


PERCENT COMPLETION ANALYSIS
---------------------------
    python docs/meta/prompts/generate_review_context.py --percent

Collates codebase + docs for percent completion analysis.
Upload files from docs/meta/prompts/percent_context/ to your LLM.
The prompt is in docs/meta/prompts/percent_completion.md


POST-IMPLEMENTATION REVIEW
--------------------------
    python docs/meta/prompts/generate_review_context.py --collate [branch-name]

Collates files for post-implementation review of a specific cycle.
If branch-name is omitted, uses the current git branch.


GENERATE CODEBASE CONTEXT ONLY
------------------------------
    python docs/meta/prompts/generate_review_context.py

Creates docs/meta/prompts/review_prompt.md with directory structure and code.


DOCUMENT FRESHNESS REPORT
-------------------------
    python docs/meta/prompts/generate_review_context.py --timestamps [output_file]

Scans docs for "Last updated:" timestamps and reports stale documents.


PROMPTS (copy to LLM as system/user instructions)
-------------------------------------------------
Planner:     docs/meta/prompts/planner_instruction.txt
Implementer: docs/meta/prompts/implementer.md
Reviewer:    docs/meta/prompts/review_instruction.txt
% Complete:  docs/meta/prompts/percent_completion.md


BUILD & TEST (Rust)
-------------------
    cargo build           # Compile
    cargo test            # Run tests (console only)
    cargo fmt             # Format current package
    rustfmt path/to/file.rs  # Preferred for targeted edits (avoid accidental workspace-wide churn)
    cargo clippy --all-targets  # Lint all targets
    cargo build --target wasm32-unknown-unknown  # WASM build

Save test output to results file (uses current branch name, works from any subdirectory):

  PowerShell:
    $root = git rev-parse --show-toplevel; $branch = git rev-parse --abbrev-ref HEAD; cargo test 2>&1 | Tee-Object -FilePath "$root/docs/meta/results/$branch.txt"

  Bash/Unix:
    cargo test 2>&1 | tee "$(git rev-parse --show-toplevel)/docs/meta/results/$(git rev-parse --abbrev-ref HEAD).txt"




# Run Criterion benchmarks with HTML reports
cd core && cargo bench

# Perf policy:
# - Routine changes: run quick (and gate if large-grid/streaming paths touched)
# - Major perf-risk changes: run full pre/post perf cycle

# Quick suite (routine)
python scripts/check_perf_thresholds.py --suite quick --parallel --baseline benchmarks/baselines/quick.json --export-json benchmarks/latest_quick.json --export-csv benchmarks/latest_quick.csv

# Gate suite (routine when large-grid/streaming paths touched)
python scripts/check_perf_thresholds.py --suite gate --parallel --baseline benchmarks/baselines/gate.json --test-target perf_large_grid_tests

# Full cycle (major changes only)
python3 scripts/perf_cycle.py pre
# ...make changes...
python3 scripts/perf_cycle.py post --cycle <cycle_id>

# Export quick metrics to JSON
python scripts/export_perf_metrics.py

# Export full-scale (50K) metrics
python scripts/export_perf_metrics.py --full-scale

# Compare two result files
python scripts/compare_perf_results.py --latest

# Build multi-metric perf history trendlines (results + perf_cycles)
python3 scripts/perf_history_trends.py --output-dir benchmarks/history

# Optional plot generation (requires matplotlib/pandas stack)
python3 scripts/perf_history_trends.py --output-dir benchmarks/history --plots
